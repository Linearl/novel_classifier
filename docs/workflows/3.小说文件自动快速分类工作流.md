# 小说文件自动快速分类工作流

## 概述

本工作流基于关键词匹配算法，实现小说文件的自动快速分类。通过读取文件前若干字符，根据预设的关键词库判断文件类型，自动将文件移动到对应分类文件夹。对于难以判断的情况，会移动到二次确认文件夹供后续人工处理。

## 🎯 工作流程目标

- **快速分类**：基于关键词匹配快速确定文件类型
- **批量处理**：一次性处理大量待分类文件
- **智能决策**：通过得分系统和阈值判断提高分类准确性
- **自动修复**：集成编码修复功能，确保文件可读性
- **质量控制**：低置信度文件自动进入二次确认流程

## 📋 适用场景

### ✅ 推荐使用情况
- 大量规范命名的小说文件需要快速分类
- 文件内容特征明显，关键词丰富
- 追求处理效率，可接受后续人工复核
- 建立初步分类体系，后续精细调整

### ❌ 不适用情况
- 文件数量较少（<30个），手动处理更高效
- 文件内容模糊，题材特征不明显
- 对分类准确性要求极高，不能容忍错误
- 创新题材或跨类别作品较多

## 🛠️ 所需工具

### 核心工具
- `main.py` - 自动分类主工作流
- `keywords_config.yaml` - 关键词配置文件
- `txt_preview.py` - 文件预览工具（内部调用）
- `encoding_fixer.py` - 编码修复工具（内部调用）

### 辅助工具
- `novel_statistics.py` - 统计分析工具
- `batch_processor.py` - 二次确认文件处理

## ⚙️ 配置系统

### 关键词权重系统
```yaml
# keywords_config.yaml 配置结构
weights:
  high: 3      # 高权重关键词得分
  medium: 2    # 中权重关键词得分
  low: 1       # 低权重关键词得分

thresholds:
  direct_classification: 16    # 直接分类阈值
  secondary_check: 8          # 二次确认阈值
  score_difference: 4         # 得分差异阈值
```

### 分类决策逻辑
```
得分 ≥ 16分 且 无竞争者 → 直接分类
得分 8-15分 → 二次确认文件夹
得分 < 8分 → 保留在待分类文件夹
有竞争者（得分差 < 4分）→ 二次确认文件夹
```

## 🚀 完整工作流程

### 阶段1：环境准备和配置检查

```bash
# 设置工作目录
cd "/Volumes/980pro/待整理"

# 检查环境和依赖
echo "=== 环境检查 ==="
python --version
python -c "import yaml, chardet; print('依赖包检查通过')"

# 检查配置文件
echo "=== 配置文件检查 ==="
if [ -f "keywords_config.yaml" ]; then
    echo "✓ 配置文件存在"
    python -c "
import yaml
with open('keywords_config.yaml', 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)
    print(f'✓ 配置加载成功')
    print(f'  - 分类数量: {len(config.get(\"categories\", {}))}')
    print(f'  - 直接分类阈值: {config.get(\"thresholds\", {}).get(\"direct_classification\", 16)}')
"
else
    echo "❌ 配置文件不存在，请检查 keywords_config.yaml"
    exit 1
fi

# 检查目录结构
echo "=== 目录结构检查 ==="
if [ ! -d "小说库" ]; then
    echo "❌ 小说库目录不存在"
    exit 1
fi

if [ ! -d "小说库/00-待分类" ]; then
    echo "❌ 待分类目录不存在"
    exit 1
fi

echo "✓ 目录结构正确"
```

### 阶段2：待分类文件统计和预检

```bash
# 统计待分类文件
echo "=== 待分类文件统计 ==="
cd "小说库/00-待分类"

total_files=$(ls *.txt 2>/dev/null | wc -l)
echo "待分类文件总数: $total_files"

if [ $total_files -eq 0 ]; then
    echo "没有待分类文件，工作流程结束"
    exit 0
fi

# 文件类型预检
echo ""
echo "=== 文件类型预检 ==="
echo "文件大小分布："
ls -la *.txt 2>/dev/null | awk '{print $5}' | sort -n | awk '
BEGIN { small=0; medium=0; large=0 }
$1 < 10000 { small++ }
$1 >= 10000 && $1 < 1000000 { medium++ } 
$1 >= 1000000 { large++ }
END { 
    printf "  小文件(<10KB): %d个\n", small
    printf "  中文件(10KB-1MB): %d个\n", medium  
    printf "  大文件(>1MB): %d个\n", large
}'

# 编码状态检查
echo ""
echo "编码状态检查："
non_utf8=$(file *.txt 2>/dev/null | grep -v "UTF-8" | wc -l)
echo "  需要编码修复: $non_utf8 个文件"

cd ../..
```

### 阶段3：执行自动分类

```bash
# 方式一：处理所有文件（推荐用于<100个文件）
echo "=== 开始自动分类处理 ==="
python main.py "小说库"

# 方式二：限制处理数量（推荐用于大量文件）
# python main.py "小说库" 50

# 方式三：使用自定义配置（如有特殊需求）
# python main.py "小说库" 50 "custom_keywords.yaml"
```

### 阶段4：处理结果分析

```bash
# 生成详细统计报告
echo "=== 分类结果统计 ==="
python novel_statistics.py

# 检查各分类文件夹状态
echo ""
echo "=== 各分类文件夹统计 ==="
categories=("01-玄幻" "02-奇幻" "03-武侠" "04-仙侠" "05-都市" "06-历史" "07-军事" "08-游戏" "09-竞技" "10-科幻" "11-灵异" "12-同人" "99-知名作者专区")

for category in "${categories[@]}"; do
    if [ -d "小说库/$category" ]; then
        count=$(ls "小说库/$category"/*.txt 2>/dev/null | wc -l)
        if [ $count -gt 0 ]; then
            echo "  $category: $count 个文件"
        fi
    fi
done

# 二次确认文件夹统计
secondary_count=$(ls "小说库/00-二次确认"/*.txt 2>/dev/null | wc -l)
echo "  00-二次确认: $secondary_count 个文件"

remaining_count=$(ls "小说库/00-待分类"/*.txt 2>/dev/null | wc -l)
echo "  00-待分类(剩余): $remaining_count 个文件"
```

### 阶段5：质量检查和验证

```bash
# 随机抽样检查分类准确性
echo "=== 分类质量抽样检查 ==="

check_category_quality() {
    local category="$1"
    local sample_size="$2"
    
    if [ ! -d "小说库/$category" ]; then
        return
    fi
    
    local files=($(ls "小说库/$category"/*.txt 2>/dev/null | head -$sample_size))
    
    if [ ${#files[@]} -eq 0 ]; then
        return
    fi
    
    echo ""
    echo "检查分类: $category (抽样 ${#files[@]} 个文件)"
    echo "----------------------------------------"
    
    for file in "${files[@]}"; do
        echo "文件: $(basename "$file")"
        echo "内容预览:"
        python txt_preview.py "$file" 500 | head -10
        echo ""
        read -p "分类是否正确？(y/n/s=跳过): " response
        case $response in
            n|N)
                echo "❌ 发现分类错误: $(basename "$file")"
                echo "请考虑调整关键词配置或手动重新分类"
                ;;
            y|Y)
                echo "✓ 分类正确"
                ;;
            s|S)
                echo "⏭️ 跳过检查"
                ;;
        esac
        echo "----------------------------------------"
    done
}

# 检查主要分类（每个抽样2个文件）
for category in "01-玄幻" "02-奇幻" "05-都市" "10-科幻"; do
    check_category_quality "$category" 2
done
```

### 阶段6：二次确认文件处理预备

```bash
# 分析二次确认文件
echo "=== 二次确认文件分析 ==="
cd "小说库/00-二次确认"

if [ $(ls *.txt 2>/dev/null | wc -l) -gt 0 ]; then
    echo "二次确认文件分类分析："
    
    # 统计不同类型的二次确认文件
    echo "  得分过低类型:"
    ls *【得分过低*.txt 2>/dev/null | wc -l
    
    echo "  得分接近类型:"
    ls *【得分接近*.txt 2>/dev/null | wc -l
    
    echo "  无匹配关键词类型:"
    ls *【无匹配关键词*.txt 2>/dev/null | wc -l
    
    echo ""
    echo "建议后续操作："
    echo "1. 运行批量处理工作流: python batch_processor.py"
    echo "2. 或使用手动分类工作流进行精确处理"
    
    # 预览一些示例文件
    echo ""
    echo "示例文件预览（前3个）："
    sample_files=($(ls *.txt 2>/dev/null | head -3))
    
    for file in "${sample_files[@]}"; do
        echo ""
        echo "--- $file ---"
        python ../../txt_preview.py "$file" 300
    done
else
    echo "✅ 无二次确认文件，所有文件已成功分类"
fi

cd ../..
```

## 📊 性能优化配置

### 批量处理参数调优

```bash
# 根据系统性能调整处理参数
optimize_processing_params() {
    local total_files=$(ls "小说库/00-待分类"/*.txt 2>/dev/null | wc -l)
    
    if [ $total_files -lt 50 ]; then
        echo "小批量模式 (${total_files}个文件): 一次性处理"
        return 0
    elif [ $total_files -lt 200 ]; then
        echo "中批量模式 (${total_files}个文件): 建议分2-3批处理"
        return 50
    else
        echo "大批量模式 (${total_files}个文件): 建议分批处理，每批50个"
        return 50
    fi
}

# 获取建议的批次大小
batch_size=$(optimize_processing_params)

if [ $batch_size -gt 0 ]; then
    echo "建议执行: python main.py \"小说库\" $batch_size"
else
    echo "建议执行: python main.py \"小说库\""
fi
```

### 关键词配置优化

```bash
# 分析关键词匹配效果
analyze_keyword_effectiveness() {
    echo "=== 关键词匹配效果分析 ==="
    
    # 统计各分类的平均得分
    python -c "
import os
import re
import glob

# 扫描二次确认文件夹，分析得分分布
pattern = r'【得分过低 \((\d+)分\)】'
scores = []

for filename in glob.glob('小说库/00-二次确认/*【得分过低*.txt'):
    match = re.search(pattern, filename)
    if match:
        scores.append(int(match.group(1)))

if scores:
    avg_score = sum(scores) / len(scores)
    print(f'得分过低文件平均得分: {avg_score:.1f}')
    print(f'最高得分: {max(scores)}')
    print(f'最低得分: {min(scores)}')
    
    # 建议阈值调整
    if avg_score > 12:
        print('建议考虑降低direct_classification阈值到14')
    elif avg_score < 8:
        print('建议考虑增加更多低权重关键词')
else:
    print('无得分过低文件，关键词库表现良好')
"
}

# 执行分析
analyze_keyword_effectiveness
```

## 🔧 高级功能

### 1. 自定义分类规则

```bash
# 创建特殊分类规则
create_custom_rules() {
    echo "=== 创建自定义分类规则 ==="
    
    # 知名作者优先分类规则
    echo "配置知名作者优先规则..."
    python -c "
import yaml

# 读取现有配置
with open('keywords_config.yaml', 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

# 添加知名作者关键词
famous_authors = ['唐家三少', '我吃西红柿', '辰东', '天蚕土豆', '猫腻', '烽火戏诸侯']

if '99-知名作者专区' not in config['categories']:
    config['categories']['99-知名作者专区'] = {
        'high_weight': famous_authors,
        'medium_weight': ['大神', '白金', '至尊'],
        'low_weight': ['经典', '完本', '精品']
    }
    
    # 保存配置
    with open('keywords_config.yaml', 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True, default_flow_style=False)
    
    print('已添加知名作者分类规则')
else:
    print('知名作者分类规则已存在')
"
}

# 创建规则
create_custom_rules
```

### 2. 动态阈值调整

```bash
# 根据处理结果动态调整阈值
adjust_thresholds_dynamically() {
    echo "=== 动态阈值调整 ==="
    
    python -c "
import yaml
import glob
import re

# 读取当前配置
with open('keywords_config.yaml', 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

# 分析二次确认文件的得分分布
scores = []
pattern = r'【得分过低 \((\d+)分\)】'

for filename in glob.glob('小说库/00-二次确认/*【得分过低*.txt'):
    match = re.search(pattern, filename)
    if match:
        scores.append(int(match.group(1)))

if scores and len(scores) > 10:
    avg_score = sum(scores) / len(scores)
    current_threshold = config['thresholds']['direct_classification']
    
    # 如果平均得分接近阈值，说明阈值可能过高
    if avg_score > current_threshold * 0.8:
        new_threshold = max(current_threshold - 2, 12)
        config['thresholds']['direct_classification'] = new_threshold
        
        with open('keywords_config.yaml', 'w', encoding='utf-8') as f:
            yaml.dump(config, f, allow_unicode=True, default_flow_style=False)
        
        print(f'阈值已从 {current_threshold} 调整为 {new_threshold}')
    else:
        print(f'当前阈值 {current_threshold} 合适，无需调整')
else:
    print('样本不足，无法进行阈值调整')
"
}

# 执行调整
adjust_thresholds_dynamically
```

### 3. 分类效果评估

```bash
# 综合评估分类效果
evaluate_classification_performance() {
    echo "=== 分类效果综合评估 ==="
    
    python -c "
import os
import glob

# 统计各类文件数量
total_files = 0
classified_files = 0
secondary_files = 0

categories = ['01-玄幻', '02-奇幻', '03-武侠', '04-仙侠', '05-都市', 
              '06-历史', '07-军事', '08-游戏', '09-竞技', '10-科幻', 
              '11-灵异', '12-同人', '99-知名作者专区']

for category in categories:
    path = f'小说库/{category}'
    if os.path.exists(path):
        count = len(glob.glob(f'{path}/*.txt'))
        classified_files += count
        total_files += count

# 二次确认文件
secondary_path = '小说库/00-二次确认'
if os.path.exists(secondary_path):
    secondary_files = len(glob.glob(f'{secondary_path}/*.txt'))
    total_files += secondary_files

# 剩余待分类文件
remaining_path = '小说库/00-待分类'
if os.path.exists(remaining_path):
    remaining_files = len(glob.glob(f'{remaining_path}/*.txt'))
    total_files += remaining_files

# 计算指标
if total_files > 0:
    auto_classification_rate = (classified_files / total_files) * 100
    secondary_rate = (secondary_files / total_files) * 100
    
    print(f'总文件数: {total_files}')
    print(f'自动分类成功率: {auto_classification_rate:.1f}%')
    print(f'二次确认率: {secondary_rate:.1f}%')
    
    # 评估等级
    if auto_classification_rate >= 80:
        print('评估等级: 优秀 ⭐⭐⭐')
    elif auto_classification_rate >= 60:
        print('评估等级: 良好 ⭐⭐')
    else:
        print('评估等级: 需要改进 ⭐')
        print('建议: 优化关键词库或降低分类阈值')
else:
    print('无文件需要处理')
"
}

# 执行评估
evaluate_classification_performance
```

## ⚠️ 注意事项和最佳实践

### 使用前检查清单
- [ ] 确认keywords_config.yaml配置文件存在且格式正确
- [ ] 检查待分类文件编码状态，必要时先运行编码修复
- [ ] 备份重要文件，特别是首次使用时
- [ ] 根据文件数量选择合适的批次大小

### 性能优化建议
1. **分批处理**：超过100个文件建议分批处理
2. **配置调优**：根据分类效果调整关键词权重和阈值
3. **定期维护**：定期更新关键词库，移除无效关键词
4. **监控内存**：处理大量文件时注意系统内存使用

### 质量保证措施
1. **抽样检查**：定期对自动分类结果进行人工抽样验证
2. **错误反馈**：发现分类错误时及时更新关键词配置
3. **版本控制**：保存关键词配置文件的不同版本
4. **日志记录**：保留详细的处理日志供问题排查

## 🚨 常见问题解决

### 问题1：大量文件进入二次确认
```bash
# 诊断和解决方案
echo "问题诊断: 大量文件进入二次确认"
echo "可能原因:"
echo "1. 关键词库不够全面"
echo "2. 分类阈值设置过高"
echo "3. 文件内容特征不明显"

echo "解决方案:"
echo "1. 分析二次确认文件，补充关键词"
echo "2. 降低direct_classification阈值"
echo "3. 增加低权重关键词数量"

# 执行关键词分析
python -c "
import glob
import re

print('\\n二次确认文件分析:')
files = glob.glob('小说库/00-二次确认/*.txt')
if files:
    print(f'总数: {len(files)}')
    
    # 统计不同类型
    low_score = len([f for f in files if '得分过低' in f])
    close_score = len([f for f in files if '得分接近' in f])
    no_match = len([f for f in files if '无匹配关键词' in f])
    
    print(f'得分过低: {low_score} ({low_score/len(files)*100:.1f}%)')
    print(f'得分接近: {close_score} ({close_score/len(files)*100:.1f}%)')
    print(f'无匹配关键词: {no_match} ({no_match/len(files)*100:.1f}%)')
"
```

### 问题2：分类准确率不高
```bash
# 提高准确率的配置优化
echo "准确率优化建议:"

# 分析错误分类模式
python -c "
print('建议的配置调整:')
print('1. 增加高权重关键词的区分度')
print('2. 设置互斥关键词规则')
print('3. 调整score_difference阈值')
print('4. 增加特定作者或系列的匹配规则')

# 生成配置建议
suggestions = {
    'high_weight_additions': {
        '01-玄幻': ['斗气', '修炼等级', '异界大陆'],
        '02-奇幻': ['魔法师', '精灵族', '西方奇幻'],
        '05-都市': ['现代都市', '重生', '商战']
    }
}

print('\\n具体关键词建议:')
for category, keywords in suggestions['high_weight_additions'].items():
    print(f'{category}: 建议添加 {keywords}')
"
```

### 问题3：处理速度慢
```bash
# 性能优化措施
echo "性能优化措施:"
echo "1. 减少每次预览的字符数量"
echo "2. 分批处理，避免内存占用过大"
echo "3. 使用更高效的关键词匹配算法"

# 监控处理性能
echo "当前系统状态:"
echo "内存使用: $(free -h 2>/dev/null | grep Mem || echo '无法获取')"
echo "磁盘空间: $(df -h . | tail -1)"
```

## 📈 后续处理建议

### 工作流程连接
```bash
echo "=== 后续处理建议 ==="
echo "1. 如有二次确认文件，运行: python batch_processor.py"
echo "2. 如需精确分类，切换到: 手动分类工作流"
echo "3. 生成最终统计: python novel_statistics.py"
echo "4. 定期备份分类结果和配置文件"
```

### 配置文件管理
```bash
# 备份当前配置
cp keywords_config.yaml "keywords_config_backup_$(date +%Y%m%d).yaml"
echo "配置文件已备份"

# 版本管理建议
echo "建议建立配置文件版本管理:"
echo "1. 记录每次修改的原因和效果"
echo "2. 保留不同版本的配置文件"
echo "3. 建立配置文件的测试和验证机制"
```

---

*最后更新：2025年6月17日*
*版本：v1.0*
*适用工具：main.py, keywords_config.yaml, txt_preview.py, encoding_fixer.py*